{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessor as prep_t\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "The aim of this notebook is to model a classifier using basinc machine learning methods and algorithms to compare its performance with more sophisticated methods/ model such as BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mislabeled = df.groupby(['text']).nunique().sort_values(by='target', ascending=False)\n",
    "df_mislabeled = df_mislabeled[df_mislabeled['target'] > 1]['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter mislabeled data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relabel manually mislabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_relabeled'] = df['target'].copy() \n",
    "df.loc[df['text'] == 'like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit', 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == 'Hellfire is surrounded by desires so be careful and donÛªt let your desires control you! #Afterlife', 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == 'To fight bioterrorism sir.', 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == '.POTUS #StrategicPatience is a strategy for #Genocide; refugees; IDP Internally displaced people; horror; etc. https://t.co/rqWuoy1fm4', 'target_relabeled'] = 1\n",
    "df.loc[df['text'] == 'CLEARED:incident with injury:I-495  inner loop Exit 31 - MD 97/Georgia Ave Silver Spring', 'target_relabeled'] = 1\n",
    "df.loc[df['text'] == '#foodscare #offers2go #NestleIndia slips into loss after #Magginoodle #ban unsafe and hazardous for #humanconsumption', 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == 'In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!', 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == 'Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\\n \\n#FARRAKHAN #QUOTE', 'target_relabeled'] = 1\n",
    "df.loc[df['text'] == 'RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG', 'target_relabeled'] = 1\n",
    "df.loc[df['text'] == \"Mmmmmm I'm burning.... I'm burning buildings I'm building.... Oooooohhhh oooh ooh...\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"wowo--=== 12000 Nigerian refugees repatriated from Cameroon\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"He came to a land which was engulfed in tribal war and turned it into a land of peace i.e. Madinah. #ProphetMuhammad #islam\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it #islam!\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"Caution: breathing may be hazardous to your health.\", 'target_relabeled'] = 1\n",
    "df.loc[df['text'] == \"I Pledge Allegiance To The P.O.P.E. And The Burning Buildings of Epic City. ??????\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"#Allah describes piling up #wealth thinking it would last #forever as the description of the people of #Hellfire in Surah Humaza. #Reflect\", 'target_relabeled'] = 0\n",
    "df.loc[df['text'] == \"that horrible sinking feeling when youÛªve been at home on your phone for a while and you realise its been on 3G this whole time\", 'target_relabeled'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['target'])\n",
    "df = df.rename(columns={'target_relabeled':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \\x89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(lambda x:re.sub(r\"(.*[a-zA-Z]?)\\x89[^\\W]*([a-zA-Z]?.*)\", r\"\\1, \\2\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean tweets using tweet preprocessing package: remove url, mention and emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_t.set_options(prep_t.OPT.URL, prep_t.OPT.EMOJI, prep_t.OPT.MENTION)\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].map(prep_t.clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remov consecutive punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequitivedots = re.compile(r'\\.{2,}')\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: consequitivedots.sub(' ... ', x))\n",
    "\n",
    "consequitivemarks = re.compile(r'\\?{2,}')\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: consequitivedots.sub('???', x))\n",
    "\n",
    "consequitivemarks = re.compile(r'\\!{2,}')\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: consequitivedots.sub('!!!', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non ascii string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "        Remove non-ASCII characters \n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: remove_non_ascii(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some special charcters and lower strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: x.replace('#', ' ').replace('@', \" \"))\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: re.sub('[^\\wÀ-ÿ\\%\\'\\.\\,\\-]', ' ', x))\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply decontraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: ' '.join(x.split()))\n",
    "df['cleaned_text'] = df['cleaned_text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sang-hoon/anaconda3/envs/minuteme/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "def lemmatization(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([d.lemma_ for d in doc])\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: lemmatization(x, nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values by an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "221 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of keywords that are frequently present in real disaster tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('keyword')['target'].mean().reset_index()\n",
    "tmp = tmp.sort_values('target', ascending = False)\n",
    "true_keywords = tmp[tmp.target > 0.5].keyword.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary column if the keyword blongs to the set or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_true_keyword'] =  df['keyword'].isin(true_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3341 unique locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3342"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean some location values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.location =='M!$$!$$!PP!', 'location'] = \"MISSISIPPI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sang-hoon/anaconda3/envs/minuteme/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gpe(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'GPE':\n",
    "            return ent.text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.location.notnull(), 'gpe_extracted'] = df.loc[df.location.notnull(), 'location'].map(extract_gpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.location.isin(['USA', 'Wordwide']), 'gpe_extracted'] =  df.loc[df.location.isin(['USA', 'Wordwide']), 'location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of locations that are frequently present in real disaster tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('gpe_extracted')['target'].mean().reset_index()\n",
    "\n",
    "tmp = tmp.sort_values('target', ascending = False)\n",
    "\n",
    "true_gpe_extracted = tmp[tmp.target > 0.5].gpe_extracted.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary column if the keyword blongs to the set or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_gpe_extracted'] = df['gpe_extracted'].isin(true_gpe_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create meta data variables such as:\n",
    "* Count of used words in a tweet\n",
    "* Mean length of words\n",
    "* Count of characters in a tweet\n",
    "* Count of punctuation characters\n",
    "* Count of hastags in a tweet\n",
    "* Count of mentions in a tweet \n",
    "* Count of url links\n",
    "* Length ouf url links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# mean_word_length\n",
    "df['mean_word_length'] = df['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# characters counts \n",
    "df['char_count'] = df['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation count\n",
    "df['punctuation_count'] = df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hastag count\n",
    "df['hashtag_count'] = df['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention count\n",
    "df['mention_count'] = df['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "\n",
    "# url count\n",
    "df['url_count'] = df['text'].apply(lambda x: len(prep_t.parse(x).urls) if np.all(pd.notnull(prep_t.parse(x).urls)) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_url(text):\n",
    "    parsed_tweet = prep_t.parse(text)\n",
    "    c= 0\n",
    "    if np.any(pd.notnull(parsed_tweet.urls)):\n",
    "        for i in range(len(parsed_tweet.urls)):\n",
    "            c = c+ len(parsed_tweet.urls[i].match)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url length\n",
    "df['len_url'] = df['text'].apply(lambda x: length_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_cleaned_text'] = df['cleaned_text'].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[['target', 'is_true_keyword',\n",
    "       'gpe_extracted', 'word_count', 'mean_word_length', 'char_count',\n",
    "       'punctuation_count', 'hashtag_count', 'mention_count', 'url_count',\n",
    "       'len_url', 'cleaned_text', 'len_cleaned_text', 'true_gpe_extracted']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['is_true_keyword'] = df_train['is_true_keyword'].map(int) \n",
    "df_train['true_gpe_extracted'] =df_train['true_gpe_extracted'].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sang-\n",
      "[nltk_data]     hoon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.33, min_df = 0.005, stop_words=stop)\n",
    "\n",
    "X = vectorizer.fit_transform(df_train.cleaned_text.values)\n",
    "X = np.concatenate((X.toarray(), df_train.drop(columns=['target', 'cleaned_text', 'gpe_extracted']).to_numpy()), axis = 1)\n",
    "\n",
    "y = df_train.target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 345)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate f1-score using cross validation to detect if the model is overfitted or not (calculate mean and standard deviation f1-score over each fold )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6       , 0.67762688, 0.68139224, 0.69308357])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=7)\n",
    "scores = cross_val_score(clf, X, y, cv=4, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.66 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the parameters are arbitrary. It is possible to do the hyper parameter tuning using grid search, bayesian optimization, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, n_jobs=-1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=7)\n",
    "\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sang-hoon/anaconda3/envs/minuteme/lib/python3.6/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "df_test['is_true_keyword'] =  df_test['keyword'].isin(true_keywords)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "df_test.loc[df_test.location.notnull(), 'gpe_extracted'] = df_test.loc[df_test.location.notnull(), 'location'].map(extract_gpe)\n",
    "\n",
    "df_test.loc[df_test.location.isin(['USA', 'Wordwide']), 'gpe_extracted'] =  df_test.loc[df_test.location.isin(['USA', 'Wordwide']), 'location']\n",
    "\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "df_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "df_test['char_count'] = df_test['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "df_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "df_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "df_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "\n",
    "df_test['url_count'] = df_test['text'].apply(lambda x: len(prep_t.parse(x).urls) if np.all(pd.notnull(prep_t.parse(x).urls)) else 0)\n",
    "\n",
    "df_test['len_url'] = df_test['text'].apply(lambda x: length_url(x))\n",
    "\n",
    "df_test = df_test.fillna('')\n",
    "\n",
    "df_test['cleaned_text']=df_test['text'].apply(lambda x:re.sub(r\"(.*[a-zA-Z]?)\\x89[^\\W]*([a-zA-Z]?.*)\", r\"\\1, \\2\", x))\n",
    "\n",
    "prep_t.set_options(prep_t.OPT.URL, prep_t.OPT.EMOJI, prep_t.OPT.MENTION)\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].map(prep_t.clean)\n",
    "\n",
    "consequitivedots = re.compile(r'\\.{2,}')\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: consequitivedots.sub(' ... ', x))\n",
    "\n",
    "consequitivemarks = re.compile(r'\\?{2,}')\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: consequitivedots.sub('???', x))\n",
    "\n",
    "consequitivemarks = re.compile(r'\\!{2,}')\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: consequitivedots.sub('!!!', x))\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: remove_non_ascii(x))\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: x.replace('#', ' ').replace('@', \" \"))\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: re.sub('[^\\wÀ-ÿ\\%\\'\\.\\,\\-]', ' ', x))\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].str.lower()\n",
    "\n",
    "df_test[\"cleaned_text\"] = df_test[\"cleaned_text\"].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "df_test['len_cleaned_text'] = df_test['cleaned_text'].map(len)\n",
    "\n",
    "df_test['true_gpe_extracted'] = df_test['gpe_extracted'].isin(true_gpe_extracted)\n",
    "\n",
    "df_test['cleaned_text'] = df_test['cleaned_text'].apply(lambda x: lemmatization(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['is_true_keyword',\n",
    "       'gpe_extracted', 'word_count', 'mean_word_length', 'char_count',\n",
    "       'punctuation_count', 'hashtag_count', 'mention_count', 'url_count',\n",
    "       'len_url', 'cleaned_text', 'len_cleaned_text', 'true_gpe_extracted']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['is_true_keyword'] = df_test['is_true_keyword'].map(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['true_gpe_extracted'] =df_test['true_gpe_extracted'].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(df_test.cleaned_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X.toarray(), df_test.drop(columns=['cleaned_text', 'gpe_extracted']).to_numpy()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = pd.read_csv('./../data/test.csv')\n",
    "#\n",
    "#output = output[['id']]\n",
    "#\n",
    "#output['target'] = predictions\n",
    "#output[['id', 'target']].to_csv('submissions_rf.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minuteme",
   "language": "python",
   "name": "minuteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
